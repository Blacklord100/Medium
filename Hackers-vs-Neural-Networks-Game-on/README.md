# Medium-Hackers-vs-Neural-Networks-Game-on

* __Author__ : Mithuran Gajendran
* __Aim__ : Make a perturbation in an image that misleads a classification DL model
* __Tools__ : We will be using VGG16 as a pretrained model and keras as a Deep Learning framework

Code for a Medium article
* Part 1 :
* Part 2 : 
* Part 3 :

# Abstract 

__Adversarial samples__ are modified images that make the network misclassify it. As seen in the article, there are different approachs. In our case, we will use __gradient maximisation approach__. It consists in iteratively adding the gradient of the targeted loss to the current image, in order to get a misclassified image.


