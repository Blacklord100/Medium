# Medium-Hackers-vs-Neural-Networks-Game-on

* Author : Mithuran Gajendran
* Aim : Make a perturbation in an image that misleads a classification DL model
* Tools : We will be using VGG16 as a pretrained model and keras as a Deep Learning framework

Code for a Medium article
* Part 1 :
* Part 2 : 
* Part 3 :

# Abstract 

Adversarial samples are modified images that make the network misclassify it. As seen in the article, there are different approachs. In our case, we will use gradient maximisation approach. It consists in iteratively adding the gradient of the targeted loss to the current image, in order to get a misclassified image.


