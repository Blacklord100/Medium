{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial example\n",
    "\n",
    "__Author :__ Mithuran Gajendran\n",
    "\n",
    "__Aim :__ Make a perturbation in an image that makes the network misclassify it\n",
    "\n",
    "__Tools :__ We will be using VGG16 as a pretrained model and keras as a Deep Learning framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from utils.preprocessing import format_img_vgg, unformat_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loaded backend as K, it is a super cool feature that allows us to code without overly think about the undergoing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial samples are modified images that makes the network misclassify it.\n",
    "As seen in the article, there are different approach. In our case, we will use gradient maximisation approach (2.8). This consists in iteratively adding the gradient of the loss with respect to the image, to the current image, in order to get a misclassified image.\n",
    "\n",
    "I will  try to keep it well explained !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's begin !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the vgg16 nn, and let's have a look to the parameters. We will need to get the last classification layer too , do not forget the include_top = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=vgg16.VGG16(weights='imagenet',include_top=True)\n",
    "#create layer dictionary to easily name them\n",
    "layer_dict = dict([ (layer.name,layer) for layer in model.layers])\n",
    "#create backend Tensor\n",
    "img_backend = model.input\n",
    "# display architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am pretty sure you have already used, or seen this network (thanks Monsieur Chollet). We are using the fully connected layers, so we have to format our input images to the correct input size [224,224]. You may use the following to load images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (colab == True):\n",
    "    !wget \"https://raw.githubusercontent.com/Blacklord100/Medium/master/Hackers-vs-Neural-Networks-Game-on/images/yann-cat.jpeg\"\n",
    "    img_in,img_visu = format_img_vgg('yann-cat.jpeg')\n",
    "    plt.imshow(img_visu)\n",
    "else:\n",
    "    try:\n",
    "        img_in,img_visu = format_img_vgg('image/yann-cat.jpeg')\n",
    "    except:\n",
    "        print('Data error: check your path')   \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Merci Yann pour ce si jolie chat](image/yann-cat.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks Yann for such a cute cat :)\n",
    "Let's verify that vgg works !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the true class by predicting it\n",
    "y_predicted = model.predict(img_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02123045</td>\n",
       "      <td>tabby</td>\n",
       "      <td>0.415729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n02124075</td>\n",
       "      <td>Egyptian_cat</td>\n",
       "      <td>0.406226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02123159</td>\n",
       "      <td>tiger_cat</td>\n",
       "      <td>0.148321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04040759</td>\n",
       "      <td>radiator</td>\n",
       "      <td>0.007515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n02127052</td>\n",
       "      <td>lynx</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1         2\n",
       "0  n02123045         tabby  0.415729\n",
       "1  n02124075  Egyptian_cat  0.406226\n",
       "2  n02123159     tiger_cat  0.148321\n",
       "3  n04040759      radiator  0.007515\n",
       "4  n02127052          lynx  0.005981"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the prediction probability with their classes\n",
    "y_predicted_decoded = vgg16.decode_predictions(y_predicted, top=5)[0]\n",
    "pd.DataFrame(y_predicted_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is definitely a tabby cat ! VGG confirmed :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient ascent maximisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our adversarial image, we have to modify an image categorized as A so that it maximises the response of our VGG network as class B at the prediction layer.\n",
    "\n",
    "And that's easy ! Conceptually, it would be the opposite of a gradient descent with a class B biased loss.  In other words, we modify our image by adding iteratively the gradient of the average response of the class we want it to be ! \n",
    "\n",
    "A pseudo-code for this would be :\n",
    "\n",
    "- img = img_in\n",
    "- for i=1:n_iters\n",
    "    - img = img + grad_step $\\nabla_{img} \\mathcal{L}$,\n",
    "    \n",
    "where $\\mathcal{L}$ is the average response of the targeted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to transform this cat slighty to make it recognised as a banana (954). In other words, we have to maximize the features of bananas into the cat image. To do so, we will start by getting the prediction layer of the VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = layer_dict['predictions'].output\n",
    "#create a function to get last layer of the VGG16 network\n",
    "get_prediction_layer = K.function([img_backend],[last_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should we define the loss that we wish to maximise ? \n",
    "\n",
    "It is the average response of the targeted class of the predicition layer. To avoid image destruction or gradient update issues, we normalise the gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_class = K.mean(last_layer[:,target_class])\n",
    "grads_class = K.gradients(loss_class,img_backend)[0]\n",
    "\n",
    "# normalize the gradient\n",
    "grads_normalised_class = grads_class / (K.maximum(K.mean(K.abs(grads_class)), K.epsilon()))\n",
    "\n",
    "# create function to retrieve loss and gradients of loss with respect to image\n",
    "get_loss_and_grads_class = K.function([img_backend],[loss_class,grads_normalised_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should reload the image, to make sure we are not starting from previous point.We included here different use cases:\n",
    "* the cat image itself\n",
    "* random noize\n",
    "* Black image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your image\n",
    "#img_in,_ = format_img_vgg('image/yann-cat.jpeg')\n",
    "#img_in = 10*np.random.randn(1,img_in.shape[1],img_in.shape[2],img_in.shape[3])\n",
    "img_in = np.full((1,img_backend.shape[1],img_backend.shape[2],img_backend.shape[3]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "step = 10  # Gradient ascent step size\n",
    "n_iterations = 50  # Number of gradient ascent steps\n",
    "for ii in range(0,n_iterations):\n",
    "    \n",
    "    loss_value,grads_value = get_loss_and_grads_class([img_in])\n",
    "    img_in = img_in + step * grads_value \n",
    "    \n",
    "    if (ii%10==0):\n",
    "        img_show = unformat_image(np.copy(img_in))\n",
    "        plt.imsave('image_dump/'+'img_out_'+str(target_class)+'_'+str(ii).zfill(3)+'.png',img_show)\n",
    "        #predict current model to see evolution of top classification\n",
    "        y_predicted = model.predict(img_in)\n",
    "        print(vgg16.decode_predictions(y_predicted, top=1)[0])\n",
    "        \n",
    "print('---Adversarial attack completed !---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, display the adversarial image\n",
    "img_show = unformat_image(np.copy(img_in))\n",
    "plt.imshow(img_show)\n",
    "#show the prediction over the adversarial image\n",
    "y_predicted = model.predict(img_in)\n",
    "print(vgg16.decode_predictions(y_predicted, top=5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in,img_visu = format_img_vgg('image/banana_cat.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(img_in)\n",
    "y_predicted_decoded = vgg16.decode_predictions(y_predicted, top=5)[0]\n",
    "print(y_predicted_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
